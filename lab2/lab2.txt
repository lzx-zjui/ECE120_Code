
Signed integer computation

1. What is the largest value representable in 16-bit signed format? Smallest?
The largest one is 32767, and the smallest one is -32768.
2. What is the result of the third computation? Why?
The result of the third computation is --22536. Because the actual value of the sum of 21000 and 22000 is bigger than the biggest value that 16-bit signed format can represent, so the overflow occurs make the value a negative number.
3. Why does the fourth computation overflow, but not the fifth?
The actual value of fourth calculation is 32768. However, the largest value represneted by 16-bit unsigned mode is 32767 (0111 1111 1111 1111). When the 32767 and 1 are added together, they got 1000 0000 0000 whose value is -32768. So the fourth computation overflow. 
For the fifth computation, -32767-1 will get -32768, and the smallest value represented by 16-bit signed mode is-32768 (1000 0000 0000), so no overflow occurs. 
4. If you were to start at 0, and increment repeatedly (add 1), what pattern would you see (in signed mode)?

Unsigned integer computation

1. What is the largest value representable in 16-bit unsigned format? Smallest?
The largest value is 65536, the smallest one is 0.
2. What result do you get from the first computation? Why?
65437. Because the 100 is 0110 0100, 199 is 1100 0111, so 100-199 get the binary value 1111 1111 1001 1101. In 16-bit unsigned mode, this binary represnetation is 65347.
3. Why doesn't the second or third computation overflow?
4. If you were to start at 0, and increment repeatedly (add 1), what pattern would you see (in unsigned mode)?
5. What are the advantages and disadvantages of unsigned formats (compared to signed formats)?

Multiplication, division, modulus

1. What result do you get in the second and third computations? Why?
The second result is -15536 and the third result is 15536. Because the actual result of these two computation exceed the biggest or smallest value that s16 and represent. So the overflow occured.
2. What results do you get from computations 4-7? Why? (Hint: can signed 16-bit encoding represent fractions?)
The result of 4th computation is 4, the results of 5th,6th,7th computations are 3.
In the 4th computation, 12 is divisible by 4. In the 7th computation, 9 is divisible by 3.In the 5,6th computation, the 11,10 is not divisible by 3, the results have fraction part. However, s16 can't represent the fraction so we only get 3 as the result.
3. Does the result from computations 4-7 get rounded to the nearest integer? If not, what actually happens? Where might this behavior be useful? (Hint: what if you wanted to divide 11 candies between 3 people?)
4. What does the modulus operator do for positive integers?
5. What happens when you divide by 0? Modulus with 0? What happens to the binary-calculator program? Why might this be a good thing? (Hint: remember the discussion introduction?)
6. Excluding division by 0, characterize the behavior of the modulus operation for positive and negative divisors and dividends (for a total of 2x2 = 4 combinations).

Floating point

1. Why is there an error in the fourth computation, but not the third? (Hint: how do you encode 0.25 and 0.3 in floating point?)
In floating point binary representation, 0.25 is exactly 0.01 while 0.3 is 0.0100110011001...(infinite loop),so the fourth computation have a error.
2. How does the result of the fifth computation compare to the fourth? Explain. (Hint: look at the hex representations of the results. How does the floating point format handle negative numbers?)
The hex representation of 96.69997 is x42c76666 and the hex representation of -99.699997 is xc2c76666. This two results' last seven are same, only the first bit is different. One is c (0100 in binary), another is 4 (1100 in binary). In f32 mode, the first bit of 32 bits play the role of representing negative(1) or positive(0). "0100" and "1100" only differs in the first bit which represents positive or negative.    
3. Mathematically, would you expect the same results in computations 6 and 7? Do you observe this result experimentally? Explain. (Hint: try stepping through each computation)
The result of 6th computation is -5.000000 and the result of 7th computation is -4.999900. The reason is that in the 6th computation, the ratio of 0.0001 to 9000 is only 1.111*10^(-7), when 9000 and 0.0001 are added, 0.0001's significand will move to right more than 24 bits which causes the 0.0001 lost. In the 7th computation, we will first add 9000 and -9005 which get -5, then we add -5 to 0.0001, this will not cause precision lost.
4. What happens if you try computation 6 in double-precision (64-bit) floating-point mode? Why?
5. Why is there noticeable error in computation 8, but not 9? (Hint: think of multiplying floating point numbers like multiplying two numbers in scientific notation, how do you do it?)
6. The root cause of the Ariane 5 rocket failure was isolated to the conversion of a floating point number, which stored the horizontal component of the rocket's velocity, to a 16-bit signed integer. What is the most likely cause of the failure? (Hint: this wasn't some small rounding error, the computed velocity was way off, causing the system to go haywire)

